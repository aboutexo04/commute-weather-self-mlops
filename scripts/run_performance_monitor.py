#!/usr/bin/env python3
"""ëª¨ë¸ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì„œë¹„ìŠ¤."""

import sys
import os
import logging
import time
import schedule
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Any

# í”„ë¡œì íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'src'))

from commute_weather.ml.mlflow_integration import MLflowManager
from commute_weather.storage.s3_manager import S3StorageManager
from commute_weather.config import ProjectPaths

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('/app/logs/performance_monitor.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


class ModelPerformanceMonitor:
    """ëª¨ë¸ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì„œë¹„ìŠ¤"""

    def __init__(self):
        self.mlflow_tracking_uri = os.getenv("MLFLOW_TRACKING_URI", "file:./mlruns")
        self.s3_bucket = os.getenv("COMMUTE_S3_BUCKET")
        self.wandb_api_key = os.getenv("WANDB_API_KEY")

        # MLflow ë§¤ë‹ˆì € ì„¤ì •
        self.mlflow_manager = MLflowManager(
            tracking_uri=self.mlflow_tracking_uri,
            experiment_name="scheduled-commute-mlops"
        )

        # S3 ë§¤ë‹ˆì € ì„¤ì • (ìˆëŠ” ê²½ìš°)
        self.s3_manager = None
        if self.s3_bucket:
            project_root = Path(__file__).resolve().parents[1]
            paths = ProjectPaths.from_root(project_root)
            self.s3_manager = S3StorageManager(paths=paths, bucket=self.s3_bucket)

        logger.info("Performance monitor initialized")

    def collect_performance_metrics(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""

        logger.info("Collecting performance metrics")

        try:
            metrics = {
                "timestamp": datetime.now().isoformat(),
                "production_model": None,
                "recent_experiments": [],
                "performance_trends": {},
                "alerts": []
            }

            # í˜„ì¬ í”„ë¡œë•ì…˜ ëª¨ë¸ ì •ë³´
            try:
                production_model = self.mlflow_manager.get_production_model("enhanced-commute-weather")
                if production_model:
                    metrics["production_model"] = {
                        "model_name": "enhanced-commute-weather",
                        "status": "available"
                    }
                else:
                    metrics["production_model"] = {
                        "model_name": "enhanced-commute-weather",
                        "status": "not_found"
                    }
                    metrics["alerts"].append("No production model found")

            except Exception as e:
                logger.warning(f"Failed to get production model: {e}")
                metrics["alerts"].append(f"Production model check failed: {str(e)}")

            # ìµœê·¼ ì‹¤í—˜ ì„±ëŠ¥
            try:
                best_run, model_uri = self.mlflow_manager.get_best_model_from_experiment()
                if best_run:
                    metrics["recent_experiments"].append({
                        "run_id": best_run.info.run_id,
                        "rmse": best_run.data.metrics.get("rmse"),
                        "mae": best_run.data.metrics.get("mae"),
                        "r2_score": best_run.data.metrics.get("r2_score"),
                        "start_time": best_run.info.start_time,
                        "status": best_run.info.status
                    })

            except Exception as e:
                logger.warning(f"Failed to get recent experiments: {e}")
                metrics["alerts"].append(f"Experiment metrics check failed: {str(e)}")

            # ì„±ëŠ¥ íŠ¸ë Œë“œ ë¶„ì„
            try:
                trend_metrics = self._analyze_performance_trends()
                metrics["performance_trends"] = trend_metrics

            except Exception as e:
                logger.warning(f"Failed to analyze trends: {e}")
                metrics["alerts"].append(f"Trend analysis failed: {str(e)}")

            logger.info(f"Collected metrics with {len(metrics['alerts'])} alerts")
            return metrics

        except Exception as e:
            logger.error(f"Failed to collect performance metrics: {e}")
            return {
                "timestamp": datetime.now().isoformat(),
                "error": str(e),
                "alerts": [f"Metrics collection failed: {str(e)}"]
            }

    def _analyze_performance_trends(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ íŠ¸ë Œë“œ ë¶„ì„"""

        try:
            # ìµœê·¼ 7ì¼ê°„ì˜ ì‹¤í—˜ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            import mlflow

            # ìµœê·¼ ì‹¤í—˜ë“¤ ì¡°íšŒ
            recent_runs = mlflow.search_runs(
                experiment_ids=[self.mlflow_manager.experiment.experiment_id],
                max_results=50,
                order_by=["start_time DESC"]
            )

            if recent_runs.empty:
                return {"status": "no_data", "message": "No recent runs found"}

            # ì„±ëŠ¥ ë©”íŠ¸ë¦­ íŠ¸ë Œë“œ ê³„ì‚°
            rmse_values = recent_runs["metrics.rmse"].dropna()
            mae_values = recent_runs["metrics.mae"].dropna()
            r2_values = recent_runs["metrics.r2_score"].dropna()

            trends = {
                "total_runs": len(recent_runs),
                "runs_with_metrics": len(rmse_values),
                "rmse_stats": {
                    "mean": float(rmse_values.mean()) if not rmse_values.empty else None,
                    "std": float(rmse_values.std()) if not rmse_values.empty else None,
                    "min": float(rmse_values.min()) if not rmse_values.empty else None,
                    "max": float(rmse_values.max()) if not rmse_values.empty else None,
                },
                "mae_stats": {
                    "mean": float(mae_values.mean()) if not mae_values.empty else None,
                    "std": float(mae_values.std()) if not mae_values.empty else None,
                    "min": float(mae_values.min()) if not mae_values.empty else None,
                    "max": float(mae_values.max()) if not mae_values.empty else None,
                },
                "r2_stats": {
                    "mean": float(r2_values.mean()) if not r2_values.empty else None,
                    "std": float(r2_values.std()) if not r2_values.empty else None,
                    "min": float(r2_values.min()) if not r2_values.empty else None,
                    "max": float(r2_values.max()) if not r2_values.empty else None,
                }
            }

            # ì„±ëŠ¥ ì €í•˜ ê°ì§€
            if len(rmse_values) >= 5:
                recent_5_rmse = rmse_values.head(5).mean()
                overall_rmse = rmse_values.mean()

                if recent_5_rmse > overall_rmse * 1.1:  # ìµœê·¼ ì„±ëŠ¥ì´ 10% ì´ìƒ ì €í•˜
                    trends["performance_alert"] = {
                        "type": "degradation",
                        "message": f"Recent RMSE ({recent_5_rmse:.4f}) is {((recent_5_rmse/overall_rmse - 1) * 100):.1f}% worse than average",
                        "recent_avg": float(recent_5_rmse),
                        "overall_avg": float(overall_rmse)
                    }

            return trends

        except Exception as e:
            logger.error(f"Trend analysis failed: {e}")
            return {"status": "error", "message": str(e)}

    def send_performance_report(self, metrics: Dict[str, Any]) -> None:
        """ì„±ëŠ¥ ë¦¬í¬íŠ¸ ì „ì†¡"""

        try:
            # WandBì— ë©”íŠ¸ë¦­ ë¡œê¹…
            if self.wandb_api_key:
                import wandb

                wandb.init(
                    project="commute-weather-monitoring",
                    name=f"performance_monitor_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                    tags=["monitoring", "performance"]
                )

                # ë©”íŠ¸ë¦­ ë¡œê¹…
                wandb_metrics = {
                    "alerts_count": len(metrics.get("alerts", [])),
                    "production_model_available": metrics.get("production_model", {}).get("status") == "available",
                    "recent_experiments_count": len(metrics.get("recent_experiments", []))
                }

                # ì„±ëŠ¥ í†µê³„ ë¡œê¹…
                trends = metrics.get("performance_trends", {})
                if "rmse_stats" in trends and trends["rmse_stats"].get("mean"):
                    wandb_metrics.update({
                        "rmse_mean": trends["rmse_stats"]["mean"],
                        "rmse_std": trends["rmse_stats"]["std"],
                        "mae_mean": trends["mae_stats"]["mean"],
                        "r2_mean": trends["r2_stats"]["mean"]
                    })

                # ì•Œë¦¼ ë‚´ìš© ë¡œê¹…
                if metrics.get("alerts"):
                    wandb_metrics["alert_messages"] = "; ".join(metrics["alerts"])

                wandb.log(wandb_metrics)
                wandb.finish()

                logger.info("Performance report sent to WandB")

            # S3ì— ë©”íŠ¸ë¦­ ì €ì¥
            if self.s3_manager:
                try:
                    self.s3_manager.store_monitoring_metrics(
                        metrics=metrics,
                        model_name="enhanced-commute-weather",
                        timestamp=datetime.now()
                    )
                    logger.info("Performance metrics stored to S3")

                except Exception as e:
                    logger.warning(f"Failed to store metrics to S3: {e}")

        except Exception as e:
            logger.error(f"Failed to send performance report: {e}")

    def check_model_health(self) -> Dict[str, Any]:
        """ëª¨ë¸ ê±´ê°•ì„± ì²´í¬"""

        logger.info("Checking model health")

        health_status = {
            "timestamp": datetime.now().isoformat(),
            "overall_health": "healthy",
            "checks": {},
            "recommendations": []
        }

        try:
            # 1. í”„ë¡œë•ì…˜ ëª¨ë¸ ì¡´ì¬ í™•ì¸
            production_model = self.mlflow_manager.get_production_model("enhanced-commute-weather")
            health_status["checks"]["production_model"] = production_model is not None

            if not production_model:
                health_status["overall_health"] = "warning"
                health_status["recommendations"].append("Deploy a production model")

            # 2. ìµœê·¼ í›ˆë ¨ í™•ì¸ (24ì‹œê°„ ì´ë‚´)
            best_run, _ = self.mlflow_manager.get_best_model_from_experiment()
            recent_training = False

            if best_run:
                last_training = datetime.fromtimestamp(best_run.info.start_time / 1000)
                hours_since_training = (datetime.now() - last_training).total_seconds() / 3600
                recent_training = hours_since_training < 24

            health_status["checks"]["recent_training"] = recent_training

            if not recent_training:
                health_status["overall_health"] = "warning"
                health_status["recommendations"].append("Consider retraining - no recent training detected")

            # 3. ëª¨ë¸ ì„±ëŠ¥ í™•ì¸
            if best_run:
                rmse = best_run.data.metrics.get("rmse", float('inf'))
                performance_ok = rmse < 0.2  # RMSE ì„ê³„ê°’

                health_status["checks"]["performance"] = performance_ok
                health_status["checks"]["rmse"] = rmse

                if not performance_ok:
                    health_status["overall_health"] = "critical"
                    health_status["recommendations"].append(f"Model performance degraded: RMSE {rmse:.4f}")

            # 4. ë°ì´í„° í’ˆì§ˆ í™•ì¸ (S3ì—ì„œ)
            if self.s3_manager:
                try:
                    recent_quality = self._check_recent_data_quality()
                    health_status["checks"]["data_quality"] = recent_quality["status"] == "good"

                    if recent_quality["status"] != "good":
                        health_status["overall_health"] = "warning"
                        health_status["recommendations"].append("Data quality issues detected")

                except Exception as e:
                    logger.warning(f"Data quality check failed: {e}")
                    health_status["checks"]["data_quality"] = None

            # ì „ì²´ ê±´ê°•ì„± í‰ê°€
            failed_checks = sum(1 for check in health_status["checks"].values()
                              if check is False)

            if failed_checks >= 2:
                health_status["overall_health"] = "critical"
            elif failed_checks >= 1:
                health_status["overall_health"] = "warning"

            logger.info(f"Model health check completed: {health_status['overall_health']}")
            return health_status

        except Exception as e:
            logger.error(f"Health check failed: {e}")
            return {
                "timestamp": datetime.now().isoformat(),
                "overall_health": "error",
                "error": str(e),
                "checks": {},
                "recommendations": ["Fix monitoring system issues"]
            }

    def _check_recent_data_quality(self) -> Dict[str, Any]:
        """ìµœê·¼ ë°ì´í„° í’ˆì§ˆ í™•ì¸"""

        try:
            # ìµœê·¼ 24ì‹œê°„ í’ˆì§ˆ ë¦¬í¬íŠ¸ ì¡°íšŒ
            recent_files = self.s3_manager.list_recent_quality_reports(hours_back=24)

            if not recent_files:
                return {"status": "no_data", "message": "No recent quality reports"}

            # ìµœì‹  í’ˆì§ˆ ì ìˆ˜ë“¤ ìˆ˜ì§‘
            quality_scores = []
            for file_path in recent_files[-10:]:  # ìµœê·¼ 10ê°œ
                try:
                    report = self.s3_manager.read_json(file_path)
                    if "feature_quality_score" in report:
                        quality_scores.append(report["feature_quality_score"])
                except:
                    continue

            if not quality_scores:
                return {"status": "no_data", "message": "No quality scores found"}

            avg_quality = sum(quality_scores) / len(quality_scores)

            if avg_quality >= 0.8:
                return {"status": "good", "average_quality": avg_quality}
            elif avg_quality >= 0.6:
                return {"status": "fair", "average_quality": avg_quality}
            else:
                return {"status": "poor", "average_quality": avg_quality}

        except Exception as e:
            return {"status": "error", "message": str(e)}

    def run_monitoring_cycle(self) -> None:
        """ëª¨ë‹ˆí„°ë§ ì‚¬ì´í´ ì‹¤í–‰"""

        logger.info("ğŸ” Running monitoring cycle")

        try:
            # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
            metrics = self.collect_performance_metrics()

            # ëª¨ë¸ ê±´ê°•ì„± ì²´í¬
            health = self.check_model_health()

            # í†µí•© ë¦¬í¬íŠ¸ ìƒì„±
            report = {
                "monitoring_cycle": datetime.now().isoformat(),
                "performance_metrics": metrics,
                "health_check": health,
                "summary": {
                    "overall_status": health["overall_health"],
                    "alerts_count": len(metrics.get("alerts", [])),
                    "recommendations_count": len(health.get("recommendations", []))
                }
            }

            # ë¦¬í¬íŠ¸ ì „ì†¡
            self.send_performance_report(report)

            logger.info(f"Monitoring cycle completed - Status: {health['overall_health']}")

        except Exception as e:
            logger.error(f"Monitoring cycle failed: {e}")

    def run_monitor(self) -> None:
        """ëª¨ë‹ˆí„°ë§ ì„œë¹„ìŠ¤ ì‹¤í–‰"""

        logger.info("ğŸš€ Starting performance monitoring service")

        # ìŠ¤ì¼€ì¤„ ì„¤ì •
        schedule.every(30).minutes.do(self.run_monitoring_cycle)  # 30ë¶„ë§ˆë‹¤ ëª¨ë‹ˆí„°ë§
        schedule.every().hour.at(":00").do(self.run_monitoring_cycle)  # ë§¤ì‹œ ì •ê°

        logger.info("Performance monitoring scheduled:")
        logger.info("  - Every 30 minutes")
        logger.info("  - Every hour at :00")

        try:
            # ì´ˆê¸° ëª¨ë‹ˆí„°ë§ ì‹¤í–‰
            self.run_monitoring_cycle()

            # ìŠ¤ì¼€ì¤„ ì‹¤í–‰
            while True:
                schedule.run_pending()
                time.sleep(60)  # 1ë¶„ë§ˆë‹¤ ì²´í¬

        except KeyboardInterrupt:
            logger.info("Performance monitor stopped by user")

        except Exception as e:
            logger.error(f"Performance monitor failed: {e}")
            raise


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""

    logger.info("ğŸ” Starting Model Performance Monitor")

    try:
        monitor = ModelPerformanceMonitor()
        monitor.run_monitor()

    except Exception as e:
        logger.error(f"Performance monitor failed: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()