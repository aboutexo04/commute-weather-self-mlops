#!/usr/bin/env python3
"""ì‹¤ì‹œê°„ MLOps íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸."""

import argparse
import logging
import os
import sys
from datetime import datetime
from pathlib import Path

# .env íŒŒì¼ ë¡œë“œ
from dotenv import load_dotenv
load_dotenv()

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ íŒŒì´ì¬ íŒ¨ìŠ¤ì— ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root / "src"))

from commute_weather.pipelines.realtime_mlops_pipeline import (
    realtime_mlops_flow,
    hourly_asos_collection_flow
)
from commute_weather.pipelines.evaluation_pipeline import model_evaluation_flow

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

logger = logging.getLogger(__name__)


def run_realtime_pipeline(args):
    """ì‹¤ì‹œê°„ MLOps íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
    print("ğŸš€ Starting realtime MLOps pipeline...")

    try:
        result = realtime_mlops_flow(
            auth_key=args.auth_key,
            station_id=args.station_id,
            use_s3=args.use_s3,
            s3_bucket=args.s3_bucket,
            s3_prefix=args.s3_prefix,
            mlflow_tracking_uri=args.mlflow_uri,
            feature_version=args.feature_version,
            use_wandb=args.use_wandb,
            wandb_project=args.wandb_project,
            wandb_entity=args.wandb_entity
        )

        if result["status"] == "success":
            print("âœ… Realtime MLOps pipeline completed successfully!")
            print(f"ğŸ“Š Prediction: {result.get('prediction_value', 'N/A'):.2f}")
            print(f"ğŸ¯ Confidence: {result.get('prediction_confidence', 0):.3f}")
            print(f"â±ï¸  Execution time: {result.get('execution_time_seconds', 0):.2f}s")
            print(f"ğŸ—“ï¸  Data timestamp: {result.get('data_timestamp', 'N/A')}")

            if args.verbose:
                print("\nğŸ“ˆ Detailed Results:")
                print(f"  - Data quality: {result.get('data_quality', 0):.1f}")
                print(f"  - Feature quality: {result.get('feature_quality', 0):.1f}")
                print(f"  - Model used: {result.get('model_used', 'N/A')}")

                s3_keys = result.get("s3_keys", {})
                if s3_keys.get("features"):
                    print(f"  - Features S3: {s3_keys['features']}")
                if s3_keys.get("prediction"):
                    print(f"  - Prediction S3: {s3_keys['prediction']}")

        else:
            print("âŒ Realtime MLOps pipeline failed!")
            print(f"Error: {result.get('error', 'Unknown error')}")
            return 1

    except Exception as e:
        print(f"âŒ Pipeline execution failed: {e}")
        logger.error(f"Pipeline execution failed: {e}", exc_info=True)
        return 1

    return 0


def run_hourly_collection(args):
    """ë§¤ì‹œê°„ ASOS ë°ì´í„° ìˆ˜ì§‘ ì‹¤í–‰"""
    print(f"ğŸ“¡ Starting hourly ASOS data collection ({args.hours_back} hours)...")

    try:
        result = hourly_asos_collection_flow(
            auth_key=args.auth_key,
            station_id=args.station_id,
            hours_back=args.hours_back,
            use_s3=args.use_s3,
            s3_bucket=args.s3_bucket
        )

        if result["status"] == "success":
            print("âœ… Hourly ASOS collection completed successfully!")
            print(f"ğŸ“Š Collected: {result.get('collected_count', 0)} observations")
            print(f"ğŸ’¾ Stored files: {len(result.get('stored_files', []))}")

            if args.verbose:
                print("\nğŸ“ Stored Files:")
                for file_info in result.get("stored_files", []):
                    if file_info["type"] == "s3":
                        print(f"  - S3: {file_info['key']}")
                    else:
                        print(f"  - Local: {file_info['path']}")

        else:
            print("âŒ Hourly ASOS collection failed!")
            return 1

    except Exception as e:
        print(f"âŒ Collection failed: {e}")
        logger.error(f"Collection failed: {e}", exc_info=True)
        return 1

    return 0


def run_model_evaluation(args):
    """ëª¨ë¸ í‰ê°€ ì‹¤í–‰"""
    print(f"ğŸ” Starting model evaluation (last {args.hours_back} hours)...")

    try:
        result = model_evaluation_flow(
            auth_key=args.auth_key,
            station_id=args.station_id,
            hours_back=args.hours_back,
            use_s3=args.use_s3,
            s3_bucket=args.s3_bucket,
            s3_prefix=args.s3_prefix,
            mlflow_tracking_uri=args.mlflow_uri,
            use_wandb=args.use_wandb,
            wandb_project=args.wandb_project,
            wandb_entity=args.wandb_entity
        )

        if result["status"] == "success":
            print("âœ… Model evaluation completed successfully!")
            print(f"ğŸ“Š Model: {result.get('model_name', 'N/A')} v{result.get('model_version', 'N/A')}")
            print(f"ğŸ¯ RÂ² Score: {result['performance_metrics'].get('r2_score', 0):.3f}")
            print(f"ğŸ“ˆ MAE: {result['performance_metrics'].get('mae', 0):.3f}")
            print(f"âš¡ Valid: {result['validation_results'].get('is_valid', False)}")
            print(f"ğŸ”„ Retraining Required: {result.get('retraining_required', False)}")
            print(f"â±ï¸  Execution time: {result.get('execution_time_seconds', 0):.2f}s")

            if args.verbose and result.get('recommendations'):
                print("\nğŸ“‹ Recommendations:")
                for rec in result['recommendations'][:3]:  # ìƒìœ„ 3ê°œë§Œ í‘œì‹œ
                    print(f"  - {rec}")

        else:
            print("âŒ Model evaluation failed!")
            print(f"Error: {result.get('error', 'Unknown error')}")
            return 1

    except Exception as e:
        print(f"âŒ Evaluation execution failed: {e}")
        logger.error(f"Evaluation execution failed: {e}", exc_info=True)
        return 1

    return 0


def run_continuous_mode(args):
    """ì—°ì† ì‹¤í–‰ ëª¨ë“œ"""
    print(f"ğŸ”„ Starting continuous mode (every {args.interval} minutes)...")

    import time
    import schedule

    def job():
        """ìŠ¤ì¼€ì¤„ëœ ì‘ì—…"""
        print(f"\nâ° {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} - Running scheduled pipeline...")

        if args.mode == "realtime":
            return run_realtime_pipeline(args)
        elif args.mode == "hourly":
            return run_hourly_collection(args)
        elif args.mode == "evaluation":
            return run_model_evaluation(args)

    # ìŠ¤ì¼€ì¤„ ì„¤ì •
    if args.interval == 60:  # 1ì‹œê°„ë§ˆë‹¤
        schedule.every().hour.do(job)
        print("ğŸ“… Scheduled to run every hour")
    else:
        schedule.every(args.interval).minutes.do(job)
        print(f"ğŸ“… Scheduled to run every {args.interval} minutes")

    # ì¦‰ì‹œ í•œ ë²ˆ ì‹¤í–‰
    if args.run_immediately:
        print("ğŸš€ Running immediately...")
        job()

    # ì—°ì† ì‹¤í–‰
    try:
        while True:
            schedule.run_pending()
            time.sleep(60)  # 1ë¶„ë§ˆë‹¤ ìŠ¤ì¼€ì¤„ í™•ì¸

    except KeyboardInterrupt:
        print("\nğŸ›‘ Continuous mode stopped by user")
        return 0


def main():
    parser = argparse.ArgumentParser(description="ì‹¤ì‹œê°„ MLOps íŒŒì´í”„ë¼ì¸ ì‹¤í–‰")

    # ê¸°ë³¸ ì„¤ì •
    parser.add_argument("mode", choices=["realtime", "hourly", "continuous", "evaluation"], help="ì‹¤í–‰ ëª¨ë“œ")
    parser.add_argument("--auth-key", help="KMA API ì¸ì¦ í‚¤")
    parser.add_argument("--station-id", default="108", help="ê¸°ìƒ ê´€ì¸¡ì†Œ ID (ê¸°ë³¸: 108-ì„œìš¸)")

    # S3 ì„¤ì •
    parser.add_argument("--use-s3", action="store_true", default=True, help="S3 ì‚¬ìš© ì—¬ë¶€")
    parser.add_argument("--s3-bucket", help="S3 ë²„í‚· ì´ë¦„")
    parser.add_argument("--s3-prefix", default="", help="S3 í‚¤ ì ‘ë‘ì‚¬")

    # MLflow ì„¤ì •
    parser.add_argument("--mlflow-uri", help="MLflow ì¶”ì  URI")
    parser.add_argument("--feature-version", default="v2", help="í”¼ì²˜ ë²„ì „")

    # WandB ì„¤ì •
    parser.add_argument("--use-wandb", action="store_true", default=True, help="WandB ì‚¬ìš© ì—¬ë¶€")
    parser.add_argument("--wandb-project", default="commute-weather-mlops", help="WandB í”„ë¡œì íŠ¸ ì´ë¦„")
    parser.add_argument("--wandb-entity", help="WandB ì—”í‹°í‹° (íŒ€ ë˜ëŠ” ì‚¬ìš©ìëª…)")

    # ì‹œê°„ ì„¤ì •
    parser.add_argument("--hours-back", type=int, default=1, help="ìˆ˜ì§‘í•  ê³¼ê±° ì‹œê°„ ìˆ˜ (hourly ëª¨ë“œìš©)")

    # ì—°ì† ì‹¤í–‰ ì„¤ì •
    parser.add_argument("--interval", type=int, default=60, help="ì—°ì† ëª¨ë“œ ì‹¤í–‰ ê°„ê²© (ë¶„)")
    parser.add_argument("--run-immediately", action="store_true", help="ì—°ì† ëª¨ë“œì—ì„œ ì¦‰ì‹œ ì‹¤í–‰")

    # ì¶œë ¥ ì„¤ì •
    parser.add_argument("--verbose", "-v", action="store_true", help="ìƒì„¸ ì¶œë ¥")

    args = parser.parse_args()

    # í™˜ê²½ë³€ìˆ˜ì—ì„œ ì„¤ì • ê°’ í™•ì¸
    if not args.auth_key:
        args.auth_key = os.getenv("KMA_AUTH_KEY")
        if not args.auth_key:
            print("âŒ KMA API ì¸ì¦ í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤. --auth-key ì˜µì…˜ì´ë‚˜ KMA_AUTH_KEY í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•˜ì„¸ìš”.")
            return 1

    if not args.s3_bucket:
        args.s3_bucket = os.getenv("COMMUTE_S3_BUCKET")
        if args.use_s3 and not args.s3_bucket:
            print("âš ï¸  S3 ë²„í‚·ì´ ì§€ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¡œì»¬ ì €ì¥ì†Œë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            args.use_s3 = False

    # ëª¨ë“œë³„ ì‹¤í–‰
    if args.mode == "continuous":
        return run_continuous_mode(args)
    elif args.mode == "realtime":
        return run_realtime_pipeline(args)
    elif args.mode == "hourly":
        return run_hourly_collection(args)
    elif args.mode == "evaluation":
        return run_model_evaluation(args)


if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)