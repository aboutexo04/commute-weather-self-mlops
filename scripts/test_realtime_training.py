#!/usr/bin/env python3
"""ì‹¤ì‹œê°„ ë°ì´í„° ê¸°ë°˜ í›ˆë ¨ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸."""

import sys
import os
import logging
from pathlib import Path
from datetime import datetime, timedelta

# í”„ë¡œì íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'src'))

from commute_weather.data.training_data_manager import RealTimeTrainingDataManager
from commute_weather.ml.enhanced_training import EnhancedCommutePredictor, EnhancedTrainingConfig
from commute_weather.ml.mlflow_integration import MLflowManager
from commute_weather.storage.s3_manager import S3StorageManager
from commute_weather.config import ProjectPaths
from commute_weather.data_sources.weather_api import WeatherObservation

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def create_mock_collected_data(storage: S3StorageManager) -> None:
    """ì‹¤ì‹œê°„ ìˆ˜ì§‘ ë°ì´í„° ëª¨ë°© (í…ŒìŠ¤íŠ¸ìš©)"""

    logger.info("Creating mock collected data for testing")

    # ì§€ë‚œ 7ì¼ê°„ì˜ ëª¨ì˜ ë°ì´í„° ìƒì„±
    end_date = datetime.now()
    start_date = end_date - timedelta(days=7)

    current_date = start_date
    while current_date <= end_date:
        try:
            # í•˜ë£¨ 24ì‹œê°„ì˜ ëª¨ì˜ KMA ë°ì´í„° ìƒì„±
            mock_kma_data = generate_mock_kma_data(current_date)

            # S3ì— ì €ì¥ (ì›ì‹œ ë°ì´í„° í˜•íƒœë¡œ)
            date_str = current_date.strftime("%Y/%m/%d")
            for hour in range(0, 24, 3):  # 3ì‹œê°„ë§ˆë‹¤
                file_timestamp = current_date.replace(hour=hour, minute=0, second=0)
                filename = f"{file_timestamp.strftime('%H%M')}.txt"

                s3_path = f"raw_data/kma/108/{date_str}/{filename}"

                # í•´ë‹¹ ì‹œê°„ì˜ KMA ì›ì‹œ ë°ì´í„° ìƒì„±
                hour_data = mock_kma_data[hour:hour+3]  # 3ì‹œê°„ì¹˜ ë°ì´í„°
                kma_raw_content = generate_kma_raw_format(hour_data, file_timestamp)

                storage.write_text(s3_path, kma_raw_content)

            logger.info(f"Created mock data for {current_date.date()}")

        except Exception as e:
            logger.warning(f"Failed to create mock data for {current_date.date()}: {e}")

        current_date += timedelta(days=1)

    logger.info("Mock data creation completed")


def generate_mock_kma_data(date: datetime) -> List[Dict]:
    """í•˜ë£¨ì¹˜ ëª¨ì˜ KMA ë°ì´í„° ìƒì„±"""

    import random
    import math

    mock_data = []

    # ê³„ì ˆì  íŒ¨í„´ (ì›”ë³„)
    month = date.month
    if month in [12, 1, 2]:  # ê²¨ìš¸
        base_temp = random.uniform(-5, 5)
        base_humidity = random.uniform(40, 70)
    elif month in [3, 4, 5]:  # ë´„
        base_temp = random.uniform(10, 20)
        base_humidity = random.uniform(50, 80)
    elif month in [6, 7, 8]:  # ì—¬ë¦„
        base_temp = random.uniform(25, 35)
        base_humidity = random.uniform(70, 90)
    else:  # ê°€ì„
        base_temp = random.uniform(15, 25)
        base_humidity = random.uniform(40, 70)

    # 24ì‹œê°„ ë°ì´í„° ìƒì„±
    for hour in range(24):
        # ì¼ì¼ ì˜¨ë„ ë³€í™” íŒ¨í„´
        hour_factor = math.sin((hour - 6) * math.pi / 12)  # ì˜¤í›„ 3ì‹œ ìµœê³ , ì˜¤ì „ 6ì‹œ ìµœì €
        temperature = base_temp + hour_factor * 5 + random.uniform(-2, 2)

        # ìŠµë„ëŠ” ì˜¨ë„ì™€ ë°˜ë¹„ë¡€ ê²½í–¥
        humidity = base_humidity - hour_factor * 10 + random.uniform(-5, 5)
        humidity = max(20, min(95, humidity))

        # ë°”ëŒê³¼ ê°•ìˆ˜ëŸ‰
        wind_speed = max(0, random.uniform(0, 8) + random.uniform(-2, 2))

        # ê°•ìˆ˜ëŸ‰ (10% í™•ë¥ ë¡œ ë¹„)
        precipitation = 0.0
        if random.random() < 0.1:
            precipitation = random.uniform(0.1, 5.0)

        # ê°•ìˆ˜ íƒ€ì…
        precip_type = "none"
        if precipitation > 0:
            if temperature <= 2:
                precip_type = "snow"
            else:
                precip_type = "rain"

        timestamp = date.replace(hour=hour, minute=0, second=0, microsecond=0)

        mock_data.append({
            "timestamp": timestamp,
            "temperature": round(temperature, 1),
            "humidity": round(humidity, 1),
            "wind_speed": round(wind_speed, 1),
            "precipitation": round(precipitation, 1),
            "precip_type": precip_type
        })

    return mock_data


def generate_kma_raw_format(data: List[Dict], start_time: datetime) -> str:
    """KMA ì›ì‹œ ë°ì´í„° í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""

    lines = []

    # í—¤ë” ì¶”ê°€
    lines.append("# KMA Weather Data")
    lines.append("# STN YYMMDDHHMI TA HM WS RN")

    for item in data:
        timestamp_str = item["timestamp"].strftime("%Y%m%d%H%M")
        line = f"108 {timestamp_str} {item['temperature']} {item['humidity']} {item['wind_speed']} {item['precipitation']}"
        lines.append(line)

    return "\n".join(lines)


def test_real_time_training_pipeline():
    """ì‹¤ì‹œê°„ í›ˆë ¨ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸"""

    logger.info("ğŸ§ª Testing real-time training pipeline")

    try:
        # í”„ë¡œì íŠ¸ ì„¤ì •
        project_root = Path(__file__).resolve().parents[1]
        paths = ProjectPaths.from_root(project_root)

        # S3 ë§¤ë‹ˆì € ì„¤ì • (í…ŒìŠ¤íŠ¸ìš© - ë¡œì»¬ íŒŒì¼ì‹œìŠ¤í…œ ì‚¬ìš©)
        s3_bucket = "test-bucket"  # ì‹¤ì œë¡œëŠ” ë¡œì»¬ ê²½ë¡œ ì‚¬ìš©
        storage = S3StorageManager(paths=paths, bucket=s3_bucket)

        # 1. ëª¨ì˜ ìˆ˜ì§‘ ë°ì´í„° ìƒì„±
        logger.info("ğŸ“ Creating mock collected data")
        create_mock_collected_data(storage)

        # 2. ì‹¤ì‹œê°„ í›ˆë ¨ ë°ì´í„° ë§¤ë‹ˆì € í…ŒìŠ¤íŠ¸
        logger.info("ğŸ“Š Testing training data manager")
        data_manager = RealTimeTrainingDataManager(
            storage_manager=storage,
            min_quality_score=0.5,  # í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ ë‚®ì¶¤
            min_observations_per_set=2
        )

        # í›ˆë ¨ ë°ì´í„° ìˆ˜ì§‘
        observation_sets, comfort_scores, stats = data_manager.collect_training_data(
            days_back=7,
            station_id="108"
        )

        print(f"\nğŸ“Š Training Data Collection Results:")
        print(f"   Observation sets: {len(observation_sets)}")
        print(f"   Total observations: {stats.total_observations}")
        print(f"   Average quality: {stats.average_quality_score:.3f}")
        print(f"   Data completeness: {stats.data_completeness:.3f}")
        print(f"   Comfort score range: {stats.comfort_score_range[0]:.3f} - {stats.comfort_score_range[1]:.3f}")

        if len(observation_sets) < 10:
            logger.warning("Insufficient training data - generating more mock data")
            # ë” ë§ì€ ëª¨ì˜ ë°ì´í„° ìƒì„±...
            return

        # 3. í–¥ìƒëœ ëª¨ë¸ í›ˆë ¨ í…ŒìŠ¤íŠ¸
        logger.info("ğŸ§  Testing enhanced model training")

        # MLflow ì„¤ì •
        mlflow_manager = MLflowManager(
            tracking_uri="file:./test_mlruns",
            experiment_name="realtime-training-test"
        )

        # í›ˆë ¨ ì„¤ì •
        config = EnhancedTrainingConfig(
            min_training_samples=10,  # í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ ë‚®ì¶¤
            test_size=0.3,
            enable_feature_selection=True,
            use_time_series_split=True,
            n_splits=3,
            max_features=20
        )

        # ì˜ˆì¸¡ê¸° ìƒì„± ë° í›ˆë ¨
        predictor = EnhancedCommutePredictor(
            config=config,
            mlflow_manager=mlflow_manager,
            s3_manager=storage
        )

        # íƒ€ì„ìŠ¤íƒ¬í”„ ìƒì„±
        timestamps = [obs[-1].timestamp for obs in observation_sets]

        # í›ˆë ¨ ë° ì¶”ì 
        run_ids = predictor.train_and_track(
            observations_list=observation_sets,
            comfort_scores=comfort_scores,
            timestamps=timestamps,
            experiment_name="realtime-training-test"
        )

        print(f"\nğŸ¯ Model Training Results:")
        print(f"   Models trained: {len(run_ids)}")
        print(f"   Best model: {predictor.best_model_name}")
        print(f"   Selected features: {len(predictor.selected_features)}")

        print(f"\nğŸ“ˆ MLflow Run IDs:")
        for model_name, run_id in run_ids.items():
            print(f"   {model_name}: {run_id}")

        # 4. ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸
        if observation_sets:
            logger.info("ğŸ”® Testing prediction with real-time data")

            # ìµœê·¼ ê´€ì¸¡ ë°ì´í„°ë¡œ ì˜ˆì¸¡
            recent_obs = data_manager.get_recent_observations_for_prediction(
                hours_back=3,
                station_id="108"
            )

            if recent_obs:
                prediction_result = predictor.predict_enhanced(recent_obs)

                print(f"\nğŸ”® Prediction Test:")
                print(f"   Input observations: {len(recent_obs)}")
                print(f"   Predicted comfort: {prediction_result['prediction']:.3f}")
                print(f"   Confidence: {prediction_result['confidence']:.3f}")
                print(f"   Model used: {prediction_result['model_used']}")
                print(f"   Feature quality: {prediction_result['feature_quality']:.3f}")

        # 5. ë°ì´í„°ì…‹ ìš”ì•½
        dataset_summary = data_manager.create_training_dataset_summary(
            observation_sets, comfort_scores, stats
        )

        print(f"\nğŸ“‹ Dataset Summary:")
        print(f"   Collection method: {dataset_summary['data_source']['collection_method']}")
        print(f"   Processing version: {dataset_summary['data_source']['processing_version']}")
        print(f"   Duration: {dataset_summary['dataset_info']['date_range']['duration_days']} days")

        logger.info("âœ… Real-time training pipeline test completed successfully!")

    except Exception as e:
        logger.error(f"âŒ Real-time training test failed: {e}")
        import traceback
        traceback.print_exc()
        raise


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""

    print("ğŸ§ª Real-Time Training Pipeline Test")
    print("=" * 50)

    try:
        test_real_time_training_pipeline()
        print("\nğŸ‰ All tests passed!")

    except Exception as e:
        print(f"\nâŒ Test failed: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()