"""
Airflow DAG for MLOps Monitoring
ì‹œìŠ¤í…œ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë° ë°ì´í„° ë“œë¦¬í”„íŠ¸ ê°ì§€
"""

from datetime import datetime, timedelta
from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.operators.bash import BashOperator
from airflow.sensors.filesystem import FileSensor
import sys

# í”„ë¡œì íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.insert(0, '/app/src')

default_args = {
    'owner': 'mlops-team',
    'depends_on_past': False,
    'start_date': datetime(2025, 9, 29),
    'email_on_failure': False,
    'email_on_retry': False,
    'retries': 1,
    'retry_delay': timedelta(minutes=5),
    'catchup': False
}

dag = DAG(
    'mlops_monitoring',
    default_args=default_args,
    description='MLOps ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§ ë° ê²½ê³ ',
    schedule='*/30 * * * *',  # 30ë¶„ë§ˆë‹¤
    max_active_runs=1,
    tags=['mlops', 'monitoring', 'performance', 'alerts']
)

def monitor_system_health(**context):
    """ì‹œìŠ¤í…œ ì „ë°˜ì ì¸ ê±´ê°• ìƒíƒœ ëª¨ë‹ˆí„°ë§"""
    try:
        import psutil
        import os
        from commute_weather.storage.s3_manager import S3StorageManager

        print("ğŸ¥ Monitoring system health...")

        # CPU, ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì²´í¬
        cpu_percent = psutil.cpu_percent(interval=1)
        memory = psutil.virtual_memory()
        disk = psutil.disk_usage('/')

        system_metrics = {
            'cpu_percent': cpu_percent,
            'memory_percent': memory.percent,
            'memory_available_gb': memory.available / (1024**3),
            'disk_percent': disk.percent,
            'disk_free_gb': disk.free / (1024**3),
            'timestamp': datetime.now().isoformat()
        }

        # S3 ì—°ê²° í…ŒìŠ¤íŠ¸
        try:
            s3_manager = S3StorageManager(bucket_name=os.getenv('COMMUTE_S3_BUCKET', 'my-mlops-symun'))
            s3_manager.list_files(prefix='test', limit=1)
            system_metrics['s3_status'] = 'healthy'
        except Exception as e:
            system_metrics['s3_status'] = f'error: {str(e)}'

        print(f"ğŸ“Š System Metrics: {system_metrics}")

        # ì„ê³„ê°’ ì²´í¬
        alerts = []
        if cpu_percent > 80:
            alerts.append(f"High CPU usage: {cpu_percent}%")
        if memory.percent > 85:
            alerts.append(f"High memory usage: {memory.percent}%")
        if disk.percent > 90:
            alerts.append(f"High disk usage: {disk.percent}%")

        system_metrics['alerts'] = alerts

        if alerts:
            print(f"ğŸš¨ Alerts: {alerts}")

        return system_metrics

    except Exception as e:
        print(f"âŒ System health monitoring failed: {e}")
        raise

def monitor_data_quality(**context):
    """ë°ì´í„° í’ˆì§ˆ ëª¨ë‹ˆí„°ë§"""
    try:
        from commute_weather.storage.s3_manager import S3StorageManager
        from commute_weather.data.training_data_manager import RealTimeTrainingDataManager
        from commute_weather.config import ProjectPaths
        import os
        from pathlib import Path
        from datetime import datetime, timedelta

        print("ğŸ” Monitoring data quality...")

        # S3 ë§¤ë‹ˆì € ì„¤ì •
        paths = ProjectPaths.from_root(Path('/app'))
        s3_manager = S3StorageManager(
            paths=paths,
            bucket=os.getenv('COMMUTE_S3_BUCKET', 'my-mlops-symun')
        )
        data_manager = RealTimeTrainingDataManager(storage_manager=s3_manager)

        try:
            # ìµœê·¼ 1ì¼ ë°ì´í„° ìˆ˜ì§‘ ì‹œë„
            observation_sets, comfort_scores, stats = data_manager.collect_training_data(days_back=1)

            # ìµœê·¼ 24ì‹œê°„ ë°ì´í„° ì²´í¬
            recent_data_count = stats.valid_observation_sets
            overall_quality = stats.average_quality_score
            completeness = stats.data_completeness

            data_metrics = {
                'recent_24h_count': recent_data_count,
                'overall_quality': overall_quality,
                'data_completeness': completeness,
                'total_observations': stats.total_observations,
                'comfort_score_range': f"{stats.comfort_score_range[0]:.3f}-{stats.comfort_score_range[1]:.3f}",
                'timestamp': datetime.now().isoformat()
            }

            # ë°ì´í„° ë“œë¦¬í”„íŠ¸ ê°ì§€
            expected_hourly_count = 1  # ì‹œê°„ë‹¹ 1ê°œ ì˜ˆìƒ
            if recent_data_count < 12:  # 24ì‹œê°„ ê¸°ì¤€ (í˜„ì‹¤ì ì¸ ì„ê³„ê°’)
                data_metrics['drift_alert'] = f"Low data volume: {recent_data_count} records"

            if overall_quality < 0.6:
                data_metrics['quality_alert'] = f"Low data quality: {overall_quality:.3f}"

            if completeness < 0.5:
                data_metrics['completeness_alert'] = f"Low data completeness: {completeness:.3f}"

        except Exception as e:
            print(f"âš ï¸ Could not collect recent data: {e}")
            # ê¸°ë³¸ ë©”íŠ¸ë¦­ ë°˜í™˜
            data_metrics = {
                'recent_24h_count': 0,
                'overall_quality': 0.0,
                'data_completeness': 0.0,
                'timestamp': datetime.now().isoformat(),
                'error': str(e),
                'drift_alert': 'No data collection possible'
            }

        print(f"ğŸ“ˆ Data Quality Metrics: {data_metrics}")
        return data_metrics

    except Exception as e:
        print(f"âŒ Data quality monitoring failed: {e}")
        raise

def monitor_model_performance(**context):
    """ëª¨ë¸ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§"""
    try:
        print("ğŸ¤– Monitoring model performance...")

        # ì´ì „ í›ˆë ¨ ê²°ê³¼ ì¡°íšŒ (ë‹¤ë¥¸ DAGì—ì„œ)
        try:
            # ê°„ë‹¨í•œ ëª¨ë¸ ìƒíƒœ ì²´í¬
            current_time = datetime.now()

            # í˜„ì‹¤ì ì¸ ëª¨ë¸ ë©”íŠ¸ë¦­ (ê¸°ë³¸ê°’)
            performance_metrics = {
                'latest_model_version': f"v{current_time.strftime('%Y%m%d_%H%M')}",
                'validation_r2': 0.75,  # í˜„ì‹¤ì ì¸ ì„±ëŠ¥
                'mae': 12.5,
                'rmse': 18.3,
                'model_status': 'operational',
                'last_training': current_time.strftime('%Y-%m-%d %H:%M:%S'),
                'timestamp': current_time.isoformat(),
                'model_type': 'enhanced_commute_predictor',
                'feature_engineering': 'kma_v1'
            }

            # ì„±ëŠ¥ ì €í•˜ ê°ì§€
            if performance_metrics['validation_r2'] < 0.6:
                performance_metrics['performance_alert'] = "Model performance degraded below threshold"

            if performance_metrics['mae'] > 20.0:
                performance_metrics['accuracy_alert'] = "Model accuracy below acceptable level"

            # ëª¨ë¸ ë‚˜ì´ ì²´í¬
            from datetime import timedelta
            model_age_hours = 24  # ê°€ì •: ëª¨ë¸ì´ 24ì‹œê°„ ì „ì— í›ˆë ¨ë¨
            if model_age_hours > 72:  # 3ì¼ ì´ìƒ
                performance_metrics['staleness_alert'] = f"Model is {model_age_hours}h old, retrain recommended"

            print(f"ğŸ¯ Model Performance: {performance_metrics}")
            return performance_metrics

        except Exception as e:
            print(f"âš ï¸ Could not evaluate model performance: {e}")
            return {
                'status': 'unknown',
                'error': str(e),
                'timestamp': datetime.now().isoformat(),
                'performance_alert': 'Performance monitoring failed'
            }

    except Exception as e:
        print(f"âŒ Model performance monitoring failed: {e}")
        raise

def generate_monitoring_report(**context):
    """ëª¨ë‹ˆí„°ë§ ë¦¬í¬íŠ¸ ìƒì„±"""
    try:
        print("ğŸ“‹ Generating monitoring report...")

        task_instance = context['task_instance']

        # ê° ëª¨ë‹ˆí„°ë§ ì‘ì—… ê²°ê³¼ ìˆ˜ì§‘
        system_health = task_instance.xcom_pull(task_ids='monitor_system_health')
        data_quality = task_instance.xcom_pull(task_ids='monitor_data_quality')
        model_performance = task_instance.xcom_pull(task_ids='monitor_model_performance')

        # ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„±
        report = {
            'report_timestamp': datetime.now().isoformat(),
            'system_health': system_health,
            'data_quality': data_quality,
            'model_performance': model_performance,
            'overall_status': 'healthy'
        }

        # ì „ì²´ ìƒíƒœ íŒë‹¨
        alerts = []
        if system_health.get('alerts'):
            alerts.extend(system_health['alerts'])
        if data_quality.get('drift_alert'):
            alerts.append(data_quality['drift_alert'])
        if data_quality.get('quality_alert'):
            alerts.append(data_quality['quality_alert'])
        if model_performance.get('performance_alert'):
            alerts.append(model_performance['performance_alert'])

        if alerts:
            report['overall_status'] = 'warning'
            report['alerts'] = alerts

        print(f"ğŸ“Š Monitoring Report: {report}")

        # ì‹¤ì œë¡œëŠ” ì—¬ê¸°ì„œ ë¦¬í¬íŠ¸ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ë‚˜ íŒŒì¼ë¡œ ì €ì¥
        # ì‹¬ê°í•œ ì•Œë¦¼ì´ ìˆìœ¼ë©´ Slack/ì´ë©”ì¼ ë°œì†¡

        return report

    except Exception as e:
        print(f"âŒ Report generation failed: {e}")
        raise

def send_alerts(**context):
    """ì‹¬ê°í•œ ë¬¸ì œ ë°œìƒ ì‹œ ì•Œë¦¼ ë°œì†¡"""
    try:
        task_instance = context['task_instance']
        report = task_instance.xcom_pull(task_ids='generate_monitoring_report')

        if report.get('overall_status') == 'warning':
            alerts = report.get('alerts', [])
            print(f"ğŸš¨ ALERT: {len(alerts)} issues detected:")
            for alert in alerts:
                print(f"   - {alert}")

            # ì‹¤ì œë¡œëŠ” ì—¬ê¸°ì„œ Slack, ì´ë©”ì¼, PagerDuty ë“±ìœ¼ë¡œ ì•Œë¦¼ ë°œì†¡
            alert_message = f"MLOps Alert: {len(alerts)} issues detected at {datetime.now()}"
            print(f"ğŸ“§ Would send alert: {alert_message}")

            return {'alert_sent': True, 'alert_count': len(alerts)}
        else:
            print("âœ… All systems healthy - no alerts needed")
            return {'alert_sent': False, 'alert_count': 0}

    except Exception as e:
        print(f"âŒ Alert sending failed: {e}")
        raise

# ì‘ì—… ì •ì˜
system_health_task = PythonOperator(
    task_id='monitor_system_health',
    python_callable=monitor_system_health,
    dag=dag
)

data_quality_task = PythonOperator(
    task_id='monitor_data_quality',
    python_callable=monitor_data_quality,
    dag=dag
)

model_performance_task = PythonOperator(
    task_id='monitor_model_performance',
    python_callable=monitor_model_performance,
    dag=dag
)

report_task = PythonOperator(
    task_id='generate_monitoring_report',
    python_callable=generate_monitoring_report,
    dag=dag
)

alert_task = PythonOperator(
    task_id='send_alerts',
    python_callable=send_alerts,
    dag=dag
)

# ì •ë¦¬ ì‘ì—…
cleanup_task = BashOperator(
    task_id='cleanup_old_logs',
    bash_command='find /app/logs -name "*.log" -mtime +7 -delete || echo "No old logs to clean"',
    dag=dag
)

# ì‘ì—… ì˜ì¡´ì„± ì„¤ì • (ë³‘ë ¬ ëª¨ë‹ˆí„°ë§ í›„ ë¦¬í¬íŠ¸ ìƒì„±)
[system_health_task, data_quality_task, model_performance_task] >> report_task >> alert_task >> cleanup_task