"""
Airflow DAG for MLOps Data Collection
ë§¤ì‹œê°„ KMA APIì—ì„œ ë‚ ì”¨ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ê³  S3ì— ì €ì¥
"""

from datetime import datetime, timedelta
from airflow import DAG
from airflow.providers.standard.operators.python import PythonOperator
from airflow.providers.standard.operators.bash import BashOperator
import sys
import os

# í”„ë¡œì íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.insert(0, '/app/src')

default_args = {
    'owner': 'mlops-team',
    'depends_on_past': False,
    'start_date': datetime(2025, 9, 29),
    'email_on_failure': False,
    'email_on_retry': False,
    'retries': 2,
    'retry_delay': timedelta(minutes=5),
    'catchup': False
}

dag = DAG(
    'kma_data_collection',
    default_args=default_args,
    description='KMA ë‚ ì”¨ ë°ì´í„° ìˆ˜ì§‘ ë° S3 ì €ì¥',
    schedule='0 * * * *',  # ë§¤ì‹œê°„ ì •ê°
    max_active_runs=1,
    tags=['mlops', 'data-collection', 'kma', 'weather']
)

def collect_weather_data(**context):
    """KMA APIì—ì„œ ë‚ ì”¨ ë°ì´í„° ìˆ˜ì§‘"""
    try:
        from commute_weather.config import KMAAPIConfig
        from commute_weather.data_sources.kma_api import fetch_recent_weather_kma
        from commute_weather.storage.s3_manager import S3StorageManager
        import requests

        print("ğŸŒ¤ï¸ Starting weather data collection...")

        # KMA API ì„¤ì •
        kma_auth_key = os.getenv('KMA_AUTH_KEY')
        if not kma_auth_key:
            raise ValueError("KMA_AUTH_KEY environment variable not set")

        config = KMAAPIConfig(
            base_url="https://apihub.kma.go.kr/api/typ01/url/kma_sfctm2.php",
            auth_key=kma_auth_key,
            station_id="108",  # ì„œìš¸ ê´€ì¸¡ì†Œ
            timezone="Asia/Seoul"
        )
        print(f"ğŸ“ Station: {config.station_id}")

        # ìµœê·¼ ë°ì´í„° ìˆ˜ì§‘ (ì§€ë‚œ 2ì‹œê°„)
        observations = fetch_recent_weather_kma(config, lookback_hours=2)

        if not observations:
            print("âš ï¸ No weather data received from KMA API")
            return {
                'observations_count': 0,
                'status': 'no_data',
                'timestamp': datetime.now().isoformat()
            }

        print(f"ğŸ“Š Collected {len(observations)} observations")

        # S3 ì €ì¥
        s3_manager = S3StorageManager(bucket_name=os.getenv('COMMUTE_S3_BUCKET', 'my-mlops-symun'))

        # ê° ê´€ì¸¡ ë°ì´í„°ë¥¼ S3ì— ì €ì¥ (Raw data)
        saved_count = 0
        for obs in observations:
            try:
                # ê´€ì¸¡ ë°ì´í„°ë¥¼ í…ìŠ¤íŠ¸ í˜•íƒœë¡œ ë³€í™˜
                obs_text = f"{obs.timestamp.strftime('%Y%m%d%H%M')},{obs.temperature_c},{obs.wind_speed_ms},{obs.precipitation_mm},{obs.relative_humidity},{obs.precipitation_type}\n"

                # S3ì— ì €ì¥
                s3_manager.store_raw_weather_data(
                    data=obs_text,
                    station_id=config.station_id,
                    timestamp=obs.timestamp,
                    source="kma",
                    metadata={
                        "temperature_c": obs.temperature_c,
                        "wind_speed_ms": obs.wind_speed_ms,
                        "precipitation_mm": obs.precipitation_mm,
                        "relative_humidity": obs.relative_humidity,
                        "precipitation_type": obs.precipitation_type
                    }
                )
                saved_count += 1
                print(f"âœ… Saved raw observation: {obs.timestamp}")
            except Exception as e:
                print(f"âš ï¸ Failed to save observation {obs.timestamp}: {e}")

        print(f"ğŸ“ˆ Successfully saved {saved_count}/{len(observations)} raw observations")

        # í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ë° ML ë°ì´í„°ì…‹ ì €ì¥
        try:
            from commute_weather.features.feature_engineering import WeatherFeatureEngineer
            import pandas as pd

            print("ğŸ§® Starting feature engineering...")
            feature_engineer = WeatherFeatureEngineer()

            ml_datasets_saved = 0
            for obs in observations:
                try:
                    # ë‹¨ì¼ ê´€ì¸¡ê°’ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë˜í•‘í•˜ì—¬ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§
                    features = feature_engineer.engineer_features([obs], obs.timestamp)

                    # DataFrameìœ¼ë¡œ ë³€í™˜
                    features_df = pd.DataFrame([features])

                    # ML ë°ì´í„°ì…‹ìœ¼ë¡œ S3ì— ì €ì¥
                    s3_manager.store_processed_features(
                        df=features_df,
                        feature_set_name="kma_weather_features",
                        version="v1",
                        timestamp=obs.timestamp
                    )

                    ml_datasets_saved += 1
                    print(f"âœ… Saved ML dataset: {obs.timestamp}")

                except Exception as e:
                    print(f"âš ï¸ Failed to create ML dataset for {obs.timestamp}: {e}")

            print(f"ğŸ§® Successfully saved {ml_datasets_saved}/{len(observations)} ML datasets")

        except Exception as e:
            print(f"âš ï¸ Feature engineering failed: {e}")
            # í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ì‹¤íŒ¨í•´ë„ raw dataëŠ” ì €ì¥ë˜ì—ˆìœ¼ë¯€ë¡œ ì „ì²´ ì‹¤íŒ¨ë¡œ ì²˜ë¦¬í•˜ì§€ ì•ŠìŒ

        return {
            'observations_count': len(observations),
            'raw_data_saved': saved_count,
            'ml_datasets_saved': ml_datasets_saved if 'ml_datasets_saved' in locals() else 0,
            'status': 'success',
            'timestamp': datetime.now().isoformat()
        }

    except Exception as e:
        print(f"âŒ Data collection failed: {e}")
        import traceback
        print(f"Full traceback: {traceback.format_exc()}")
        raise

def validate_data_quality(**context):
    """ìˆ˜ì§‘ëœ ë°ì´í„°ì˜ í’ˆì§ˆ ê²€ì¦"""
    try:
        from commute_weather.storage.s3_manager import S3StorageManager

        print("ğŸ” Starting data quality validation...")

        s3_manager = S3StorageManager(bucket_name=os.getenv('COMMUTE_S3_BUCKET', 'my-mlops-symun'))

        # ì´ì „ ì‘ì—…ì—ì„œ ìˆ˜ì§‘ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
        task_instance = context['task_instance']
        collection_result = task_instance.xcom_pull(task_ids='collect_weather_data')

        if not collection_result:
            print("âš ï¸ No collection result found")
            return {'overall': 0.0, 'status': 'no_data'}

        raw_data_saved = collection_result.get('raw_data_saved', 0)
        ml_datasets_saved = collection_result.get('ml_datasets_saved', 0)
        total_count = collection_result.get('observations_count', 0)

        # ê°„ë‹¨í•œ í’ˆì§ˆ í‰ê°€
        if total_count == 0:
            raw_completeness = 0.0
            ml_completeness = 0.0
        else:
            raw_completeness = raw_data_saved / total_count
            ml_completeness = ml_datasets_saved / total_count

        # ê¸°ë³¸ì ì¸ í’ˆì§ˆ ë©”íŠ¸ë¦­
        quality_result = {
            'raw_data_completeness': raw_completeness,
            'ml_data_completeness': ml_completeness,
            'consistency': 0.98,  # ê°€ì •ê°’
            'timeliness': 0.92,   # ê°€ì •ê°’
            'total_observations': total_count,
            'raw_data_saved': raw_data_saved,
            'ml_datasets_saved': ml_datasets_saved,
            'overall': (raw_completeness * 0.4 + ml_completeness * 0.4 + 0.95 * 0.2)  # weighted average
        }

        print(f"ğŸ“Š Quality Results: {quality_result}")

        # í’ˆì§ˆì´ ë„ˆë¬´ ë‚®ìœ¼ë©´ ì•Œë¦¼
        if quality_result['overall'] < 0.8:
            print("âš ï¸ Data quality below threshold!")
        else:
            print("âœ… Data quality acceptable")

        return quality_result

    except Exception as e:
        print(f"âŒ Data validation failed: {e}")
        import traceback
        print(f"Full traceback: {traceback.format_exc()}")
        raise

def update_data_catalog(**context):
    """ë°ì´í„° ì¹´íƒˆë¡œê·¸ ì—…ë°ì´íŠ¸"""
    try:
        print("ğŸ“‹ Updating data catalog...")

        # ë°ì´í„° ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸
        task_instance = context['task_instance']
        collection_result = task_instance.xcom_pull(task_ids='collect_weather_data')
        quality_result = task_instance.xcom_pull(task_ids='validate_data_quality')

        catalog_entry = {
            'timestamp': datetime.now().isoformat(),
            'source': 'KMA API',
            'observations_count': collection_result.get('observations_count', 0),
            'quality_score': quality_result.get('overall', 0),
            'status': 'success'
        }

        print(f"ğŸ“Š Catalog Entry: {catalog_entry}")

        # ì—¬ê¸°ì„œ ì‹¤ì œë¡œëŠ” ë°ì´í„°ë² ì´ìŠ¤ë‚˜ ë©”íƒ€ë°ì´í„° ìŠ¤í† ì–´ì— ì €ì¥

        return catalog_entry

    except Exception as e:
        print(f"âŒ Catalog update failed: {e}")
        raise

# ì‘ì—… ì •ì˜
collect_task = PythonOperator(
    task_id='collect_weather_data',
    python_callable=collect_weather_data,
    dag=dag
)

validate_task = PythonOperator(
    task_id='validate_data_quality',
    python_callable=validate_data_quality,
    dag=dag
)

catalog_task = PythonOperator(
    task_id='update_data_catalog',
    python_callable=update_data_catalog,
    dag=dag
)

# í—¬ìŠ¤ì²´í¬ ì‘ì—…
health_check = BashOperator(
    task_id='health_check',
    bash_command='echo "ğŸ¥ Data collection pipeline health check completed"',
    dag=dag
)

# ì‘ì—… ì˜ì¡´ì„± ì„¤ì •
collect_task >> validate_task >> catalog_task >> health_check